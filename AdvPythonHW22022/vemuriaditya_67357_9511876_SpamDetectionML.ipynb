{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamDetectionML.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the Spam Detection Filter with ML"
      ],
      "metadata": {
        "id": "kYBass2G-mEg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4REu_zw-UdU",
        "outputId": "f83c381a-4460-453c-f5b7-c7777729cb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572, 5)\n",
            "Index(['v1', 'v2', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], dtype='object')\n",
            "Accuracy: 0.007174887892376682\n"
          ]
        }
      ],
      "source": [
        "#importing the necessary libraries and packages\n",
        "import pandas as pd #the data sets\n",
        "from sklearn.model_selection import train_test_split #sklearn stuff\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import svm \n",
        "\n",
        "\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/SmallLion/Python-Projects/main/Spam-detection/spam.csv' #the raw data\n",
        "spam = pd.read_csv(url) #creating a data set with pandas\n",
        "print(spam.shape)\n",
        "print(spam.columns) \n",
        "\n",
        "#now dividing the training data and the testing data\n",
        "z = spam['v1'] #the column of actual email text is assigned to \"z\"\n",
        "y = spam[\"v2\"]     #the column of the labels (ham/spam) is assigned to \"y\"\n",
        "z_train, z_test,y_train, y_test = train_test_split(z,y,test_size = 0.2) #splits the data into training and testing (80/20)\n",
        "\n",
        "\n",
        "\n",
        "cv = CountVectorizer() #similar to one of the problems you assigned us in the beginning, this counts number of occurences of each unique word\n",
        "features = cv.fit_transform(z_train) #assigns a number to each word, then counts occurences of the word in the email | now it can find trends of certain word occurences in spam emails\n",
        "\n",
        "model = svm.SVC() #using a SVM model because this type of model allows for machines to classify data into 2 distinct groups and predict how other data might be classified\n",
        "model.fit(features,y_train) #takes the features (email content) and compares it against y_train (ham/spam) and then adjusts to max accuracy\n",
        "\n",
        "\n",
        "\n",
        "features_test = cv.transform(z_test) #now creating a test data set that counts occurences of each word\n",
        "print(\"Accuracy: {}\".format(model.score(features_test,y_test))) #finding the accuracy of our model with the test data set\n",
        "\n"
      ]
    }
  ]
}