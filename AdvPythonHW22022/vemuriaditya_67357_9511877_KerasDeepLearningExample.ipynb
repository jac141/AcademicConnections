{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasDeepLearningExample.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning with Keras"
      ],
      "metadata": {
        "id": "Bx3Bg9VqDxm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From what I've read, my conceptual understanding of Deep Learning is a subset of machine learning that tries to mimic the process by which the human brain learns. It uses layers of abstraction each of which finetunes the patterns that the alogrithm is understanding. \n",
        "\n",
        "\n",
        "In this project, the objective is to classify handwritten digits. Using a neural network to identify the patterns in the images, it will then coalesce those patterns to produce an answer that I hope to be the actual number in the image. "
      ],
      "metadata": {
        "id": "1yimj0LPD6rm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "Vj-2kUl5DvJG",
        "outputId": "08f1671b-c8ed-4f00-992e-f842ba6fb132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.21.6\n",
            "(60000, 28, 28)\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 121s 64ms/step - loss: 0.2047 - accuracy: 0.9393\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 119s 63ms/step - loss: 0.0843 - accuracy: 0.9744\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 118s 63ms/step - loss: 0.0663 - accuracy: 0.9792\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 117s 63ms/step - loss: 0.0540 - accuracy: 0.9831\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 117s 63ms/step - loss: 0.0454 - accuracy: 0.9859\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 117s 63ms/step - loss: 0.0403 - accuracy: 0.9874\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 117s 63ms/step - loss: 0.0360 - accuracy: 0.9889\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 117s 62ms/step - loss: 0.0328 - accuracy: 0.9893\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 117s 62ms/step - loss: 0.0301 - accuracy: 0.9905\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 117s 62ms/step - loss: 0.0279 - accuracy: 0.9911\n",
            "[0.02563381940126419, 0.993399977684021]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#importing the relevant libraries and packages\n",
        "\n",
        "import matplotlib\n",
        "print( np.__version__)\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(123)  #to ensure reproducibility\n",
        " \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist #the library of training data\n",
        "\n",
        "\n",
        "#next step is classifying training and testing data\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data() #this is the training and test data\n",
        "print( X_train.shape ) # there are 60,000 training images, each of which is 28 by 28 pixels\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(X_train[0])\n",
        "\n",
        "#changing the images to only have 1 channel (channel = color --> making it black and white)\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "#converting the data type to float32 to ensure accuracy and then normalizing the data\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "#problem with class label data is that it is a 1 dimensional array\n",
        "#but we need 10 distinctive classes for each of the digits that the image could be\n",
        "\n",
        "# converts the 1D array into a 10 class matrice\n",
        "Y_train = np_utils.to_categorical(y_train, 10) #the to_categorical() function converts a class of integers to a binary class matrix, \n",
        "Y_test = np_utils.to_categorical(y_test, 10) \n",
        "\n",
        "#going to be implementing a sequential model for the neural network\n",
        "#it is a model where each previous layer is the input to the current layer\n",
        "#each layer will pick up on more and more distinct patterns until it can eventually classify the image as a certain number\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
        "#the line above tells the model how many @D convolution filters to add\n",
        "#the purpose of these is to find distinct patterns in the 2D images provided\n",
        "    #it will find these patterns in 3x3 chunks as specified in the code\n",
        "    #the \"relu\" part serves as an activation function for the network\n",
        "model.add(Convolution2D(32, (3,3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#MaxPooling2D serves as a way to accentuate the bright parts of the image so that the model can more easily pick up on the patterns in the images\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "#to prevent overfitting to the training data, they add this line of code which randomly changes neurons to 0 which decreases the complexity\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "#converts the multidimensional arrays fo data to a single dimensionial array to pass the data effectively between every single neuron\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#how the model connects layers and adjusts the biases in each neuron ? ~ this part I'm iffy on\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "#softmax will give the probability for each of our class labels (from 1-10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "#lots of videos to understand loss, but essentially... the loss(or cost) function is how the model learns how bad it is at identifying the images\n",
        "#it slowly optimizes itself using a loss function and a method called \"backpropagation gradient descent\" to work backwards and adjust the biases\n",
        "#and weights in the neurons until it achieves a minimum loss (as accurate as possible using so much calculus)\n",
        "\n",
        "#telling the model to take the data and process it in batches to speed up computational efficiency\n",
        "model.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "#testing the accuracy of the model\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "print(score)\n",
        "\n",
        "\n"
      ]
    }
  ]
}