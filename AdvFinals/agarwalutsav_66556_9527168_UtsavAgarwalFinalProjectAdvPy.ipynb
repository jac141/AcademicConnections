{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d9ce36c-bdc1-4d99-b19a-1dd5155bf62b",
   "metadata": {},
   "source": [
    "My name is Utsav Agarwal, and some of the things I am interested in are Rubik's Cubes and Astronomy.\n",
    "\n",
    "I have written a program that shows the correlations between a star's temperature, luminosity, radius, and absolute magnitude and the star's color. The code also tests a few different machine learning algorithms to see which one would fit the model the best. I decided to use this dataset and do this project because the dataset I found on Kaggle looked really interesting. After talking to JoJo during office hours, he suggested I answer the question, \"Does having more features in your dataset always result in a better model?\"\n",
    "\n",
    "I only have one codebox with my final code, but I added comments throughout explaining what that section did and any changes I had to make. There is also a section at the end where I answer the question above, list 2 problems I faced, and list some of the extra resources I used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7718d86a-6bf7-496a-8213-df6620d6793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e110b833-400c-457c-9c0e-43d4f15d44ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING MODELS\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "1. Accuracy Score of KNN (Temperature+Luminosity->Color) is 0.7708333333333334\n",
      "2. Accuracy Score of KNN (Temperature->Color) is 0.7916666666666666\n",
      "3. Accuracy Score of KNN (Luminosity->Color) is 0.6875\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "4. Accuracy Score of Random Forest (Temperature+Luminosity->Color) is 0.8333333333333334\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "5. Accuracy Score of Decision Tree (Temperature+Luminosity->Color) is 0.7916666666666666\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "TESTING FEATURES\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "6. Accuracy Score of Random Forest (Temperature->Color) is 0.7708333333333334\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "7. Accuracy Score of Random Forest (Luminosity->Color) is 0.6458333333333334\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "8. Accuracy Score of Random Forest (Temperature+Luminosity+Radius->Color) is 0.8958333333333334\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "9. Accuracy Score of Random Forest (Temperature+Luminosity+Radius+Absolute Magnitude->Color) is 0.875\n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Task complete. Thank you.\n",
      "Program made by Utsav Agarwal\n"
     ]
    }
   ],
   "source": [
    "og_df = pd.DataFrame(pd.read_csv('Stars.csv'))\n",
    "\n",
    "\"\"\"\n",
    "The Color feature of the dataset had a lot of colors that were essentially the same but used different names\n",
    "This next part is where I went and made all the colors similar to each other have the same name\n",
    "\"\"\"\n",
    "#Change colors related to yellow and white to Yellowish White\n",
    "og_df = og_df.replace(to_replace=\"White Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"Yellowish\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"White-Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"White Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"Whitish\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"White\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"white Yellow\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"yellowish\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"white\", value=\"yellow-white\")\n",
    "og_df = og_df.replace(to_replace=\"yellow-white\", value=\"Yellowish White\")\n",
    "#Change colors related to orange to Orange\n",
    "og_df = og_df.replace(to_replace=\"Pale yellow orange\", value=\"Orange\")\n",
    "og_df = og_df.replace(to_replace=\"Orange-Red\", value=\"Orange\")\n",
    "#Change Blue-white to Blue White\n",
    "og_df = og_df.replace(to_replace=\"Blue-white\", value=\"Blue White\")\n",
    "og_df = og_df.replace(to_replace=\"Blue-White\", value=\"Blue White\")\n",
    "\n",
    "\"\"\"\n",
    "I create dataframes with the features I intend on using\n",
    "I turn the color dataframe to a NumPy array so I can use .ravel(), which changes the shape of the dataframe to suit the Machine Learning Models\n",
    "\"\"\"\n",
    "T = og_df[['Temperature']].copy()\n",
    "L = og_df[['L']].copy()\n",
    "color = og_df[['Color']].copy()\n",
    "color = color.to_numpy()\n",
    "radius = og_df[['R']].copy()\n",
    "absolute_magnitude = og_df[['A_M']].copy()\n",
    "\n",
    "\"\"\"\n",
    "I use .train_test_split() to create the train and test sets for the features I intended on using: Temperature, Luminosity (L)*, Relative Radius (R)*, Absolute Magnitude (A_M), and color\n",
    "I then make the dataframes that have the combination of the features I want to use to predict the color\n",
    "\n",
    "If the beginning of the variable name has:\n",
    "TL - Combination of Temperature and Luminosity\n",
    "TLR - Combination of Temperature, Luminosity, and Relative Radius\n",
    "TLRA - Combination of Temperature, Luminosity, Relative Radius, and Absolute Magnitude\n",
    "\n",
    "If the variable name has 'C' after the letters above, it refers to the Machine Learning model created\n",
    "\n",
    "\n",
    "*Luminosity and Radius here are relative to the Sun\n",
    "\"\"\"\n",
    "temp_train, temp_test, l_train, l_test, color_train, color_test, radi_train, radi_test, mag_train, mag_test= train_test_split(T, L, color, radius, absolute_magnitude, test_size = 0.2)\n",
    "TL_train = pd.concat([temp_train, l_train], axis=1)\n",
    "TL_test = pd.concat([temp_test, l_test], axis=1)\n",
    "TLR_train = pd.concat([temp_train, l_train, radi_train], axis=1)\n",
    "TLR_test = pd.concat([temp_test, l_test, radi_test], axis=1)\n",
    "TLRA_train = pd.concat([temp_train, l_train, radi_train, mag_train], axis=1)\n",
    "TLRA_test = pd.concat([temp_test, l_test, radi_test, mag_test], axis=1)\n",
    "\n",
    "color_train = color_train.ravel()\n",
    "\n",
    "\"\"\"\n",
    "Before comparing the features, I had to find the best model to use\n",
    "I trid K Nearest Neighbors first, but the accuracy of the model was lower than anticipated\n",
    "The Random Forest model yielded a much better accuracy\n",
    "The Decision Tree model was better than KNN, but not as good as Random Forest*\n",
    "\n",
    "*This is most likely because the Random Forest Machine Learning Model utilizes multiple Decision Trees within its algorithm, making it a more refined version of it\n",
    "\"\"\"\n",
    "print(\"TESTING MODELS\")\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "#Testing different models, K Nearest Neighbors\n",
    "n=8\n",
    "TLC = KNeighborsClassifier(n_neighbors = n)\n",
    "TLC.fit(TL_train, color_train)\n",
    "TLC_pre = TLC.predict(TL_test)\n",
    "\n",
    "print(\"1. Accuracy Score of KNN (Temperature+Luminosity->Color) is {}\".format(accuracy_score(color_test, TLC_pre)))\n",
    "\n",
    "\"\"\"\n",
    "Before trying other models, I wanted to make sure that the low accuracy score wasn't due to the data (as in the star's temperature and luminosity didn't correlate with\n",
    "its color), so I tried the KNN model with just Temperature and Luminosity. Both models were at about the same accuracy, or lower, so I knew the problem was with the model.\n",
    "It was here that I discoverd I initially made a mistake with the replace statements I used earlier, and was able to clean up the data properly.\n",
    "\"\"\"\n",
    "TC = KNeighborsClassifier(n_neighbors = n)\n",
    "TC.fit(temp_train, color_train)\n",
    "TC_pre = TC.predict(temp_test)\n",
    "\n",
    "print(\"2. Accuracy Score of KNN (Temperature->Color) is {}\".format(accuracy_score(color_test, TC_pre)))\n",
    "\n",
    "LC = KNeighborsClassifier(n_neighbors = n)\n",
    "LC.fit(l_train, color_train)\n",
    "LC_pre = LC.predict(l_test)\n",
    "\n",
    "print(\"3. Accuracy Score of KNN (Luminosity->Color) is {}\".format(accuracy_score(color_test,LC_pre)))\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# Testing Random Forest\n",
    "rTLC = RandomForestClassifier(max_depth = 4)\n",
    "rTLC.fit(TL_train, color_train)\n",
    "rTLC_pre = rTLC.predict(TL_test)\n",
    "\n",
    "print(\"4. Accuracy Score of Random Forest (Temperature+Luminosity->Color) is {}\".format(accuracy_score(color_test, rTLC_pre)))\n",
    "\"\"\"\n",
    "The accuracy ranges of the Random Forest Model are at a nice level, from 0.8 - 0.95. I decided to try one more model to see if I could improve the accuracy.\n",
    "\"\"\"\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "# Trying Decision Tree\n",
    "dTLC = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "dTLC.fit(TL_train, color_train)\n",
    "dTLC_pre = dTLC.predict(TL_test)\n",
    "\n",
    "print(\"5. Accuracy Score of Decision Tree (Temperature+Luminosity->Color) is {}\".format(accuracy_score(color_test, dTLC_pre)))\n",
    "\n",
    "\"\"\"\n",
    "The accuracy of the Decision Tree model was lower than that of the Random Forest, from 0.75 - 0.85. This makes sense, as I learned later that the\n",
    "Random Forest algorithm uses multiple Decision Trees, hence the name forest. So there was a high chance of this model having a lower accuracy than\n",
    "that of the Random Forest.\n",
    "\"\"\"\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "print('TESTING FEATURES')\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\"\"\"\n",
    "With the model decided, I wanted to check the relationships between different features of a star and it's color.\n",
    "I started by testing models that only use Temperature and only use Luminosity, and added on the Relative Radius and Absolute Magnitude to see if they\n",
    "had an affect on the accuracy. \n",
    "\"\"\"\n",
    "\n",
    "rTC = RandomForestClassifier(max_depth = 4)\n",
    "rTC.fit(temp_train, color_train)\n",
    "rTC_pre = rTC.predict(temp_test)\n",
    "\n",
    "print(\"6. Accuracy Score of Random Forest (Temperature->Color) is {}\".format(accuracy_score(color_test, rTC_pre)))\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "rLC = RandomForestClassifier(max_depth = 4)\n",
    "rLC.fit(l_train, color_train)\n",
    "rLC_pre = rLC.predict(l_test)\n",
    "\n",
    "print(\"7. Accuracy Score of Random Forest (Luminosity->Color) is {}\".format(accuracy_score(color_test,rLC_pre)))\n",
    "\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\"\"\"\n",
    "With the accuracy of the Temperature and Luminosity solo models being lower than the model which included both, I started to add Relative Radius to the \n",
    "model to see its effect.\n",
    "\"\"\"\n",
    "\n",
    "rTLRC = RandomForestClassifier(max_depth = 4)\n",
    "rTLRC.fit(TLR_train, color_train)\n",
    "rTLRC_pre = rTLRC.predict(TLR_test)\n",
    "\n",
    "print(\"8. Accuracy Score of Random Forest (Temperature+Luminosity+Radius->Color) is {}\".format(accuracy_score(color_test, rTLRC_pre)))\n",
    "\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "\"\"\"\n",
    "The model with Temperature, Luminosity, and Relative Radius had an accuracy of about 87.5 - 98, so I believe the relative radius of a star had a slight effect on its color.\n",
    "With that completed, I added Absolute Magnitude to the model to see if that had any effect.\n",
    "\"\"\"\n",
    "rTLRAC = RandomForestClassifier(max_depth = 4)\n",
    "rTLRAC.fit(TLRA_train, color_train)\n",
    "rTLRAC_pre = rTLRAC.predict(TLRA_test)\n",
    "\n",
    "print(\"9. Accuracy Score of Random Forest (Temperature+Luminosity+Radius+Absolute Magnitude->Color) is {}\".format(accuracy_score(color_test, rTLRAC_pre)))\n",
    "\n",
    "\"\"\"\n",
    "The model with Absolute Magnitude included with Temperature, Luminosity, and Relative Radius had an accuracy that was usually lower than that of the model without it, sometimes\n",
    "equal, and rarely higher. So I conclude that Absolute Magnitude doesn't have an effect on a star's color.\n",
    "\"\"\"\n",
    "print('------------------------------------------------------------------------------------------------------------------')\n",
    "print('Task complete. Thank you.')\n",
    "print('Program made by Utsav Agarwal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0b589-6f52-4802-affa-3987e6420c87",
   "metadata": {},
   "source": [
    "-------\n",
    "Question: Does having more features always result in a better model?\n",
    "\n",
    "The answer I got to the question is no. While it is often true, seen by the models with only one feature (Models 6 and 7) having the lowest accuracy, the accuracy of Model 9, which has the most features, shows that it isn't always true. This could be due to the fact that the feature Absolute Magnitude doesn't have any effect on the color of the star. \n",
    "\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f390fd38-c50a-4187-9492-19c03a10886c",
   "metadata": {},
   "source": [
    "Problems I Faced:\n",
    "\n",
    "Problem 1:\n",
    "\n",
    "I faced my first problem when I was starting to test out the models. I couldn't get any of them to work because of an error where the .fit() method was expecting 1d array but an array with a different shape was passed. I searched up the error on stackoverflow and saw the solution was in the method .ravel(). The .ravel() method changes the shape of a NumPy array to be 1d.\n",
    "\n",
    "The error message I encountered: \"DataConversionWarning: A column-vector y was passed when a 1d array was expected.\"\n",
    "\n",
    "Problem 2:\n",
    "\n",
    "After the KNN models weren't as accurate as I had hoped, and after I found out that the problem wasn't with how well the temperature and luminosity features correlated with color, I displayed the different train and test sets to see if the problem lay in the data. It turns out that the .replace() functions I was previously using weren't doing what they were supposed to, and the train and test sets still had to deal with weirdly named colors. I checked on stackoverflow and the Pandas documentation, and it turns out I was using them wrong. I had to set the dataframe equal to itself after I replaced the color names.\n",
    "\n",
    "What I was doing before: og_df.replace(to_replace=\"Blue-White\", value=\"Blue White\")\n",
    "\n",
    "What I had to do: og_df = og_df.replace(to_replace=\"Blue-White\", value=\"Blue White\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4248ee-c721-4962-938e-ba5691084e40",
   "metadata": {},
   "source": [
    "----------\n",
    "Extra Sources I Used in this Project:\n",
    "\n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html                                (and other pages on the Pandas Documentation)\n",
    "\n",
    "https://www.kaggle.com/datasets/brsdincer/star-type-classification                                        (Dataset)\n",
    "\n",
    "stackoverflow.com                                                                                         (Reference)\n",
    "\n",
    "https://medium.com/codex/credit-card-fraud-detection-with-machine-learning-in-python-ac7281991d87         (Reference)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html           (and other pages on the Sklearn Documentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
