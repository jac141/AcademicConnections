{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Classification of Automobile parts\n\nThis notebook builds an end-end multiclass image classifier using Tensorflow 2.0 and TensorFlow Hub.\n\n## 1. Problem\n  Identifying the automobile parts given an image.\n\n## 2.The data we are using is from `Kaggle`\nhttps://www.kaggle.com/datasets/mdwaquarazam/automobilepartsindentification\n\n## 3. Evaluation\nFor each image in the test set, you must predict a probability for each of the different breeds. The evaluation is the file with the prediction probabilities with the image of each dog of each test image.\n\n## 4.Features\nthere are 689 images in the dataset and we will use 50% of the image to train the model.these data is having a label. Test images are not having any labels.","metadata":{"id":"SObfdxgI4Mah"}},{"cell_type":"markdown","source":"### Get our workspace ready","metadata":{"id":"7aQzIhhJATAA"}},{"cell_type":"code","source":"# Import Tensorflow into Colab \n# Import Tensorflow Hub\n# Make sure we are using GPU.\n# Importing necessary tools","metadata":{"id":"67hF9V4f4C16"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\nprint(\"TensorFlow Version is : \" ,tf.__version__)\nprint(\"TensorFlow Hub Version: \", hub.__version__)","metadata":{"id":"ErwQIAb4Av_g","outputId":"ef7c79fd-1f5b-492b-fe1e-730bd524b818"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for GPU Availability\nprint(\"GPU is available (YESSSSSSSS !!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"Not available\")","metadata":{"id":"4-Qk7qERAyIr","outputId":"a2270e20-2fba-40f2-d2aa-6bc915616856"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting our data ready , turing them into **Tensors**.","metadata":{"id":"QeqfTmMwCNen"}},{"cell_type":"code","source":"#Checkout the labels of our data.\nimport pandas as pd\ndata_dir ='../input/automobilepartsindentification/Automobile-parts,.Typecast.csv'\nlabels = pd.read_csv(data_dir)\nprint(labels.describe)","metadata":{"id":"oTyiCdbZA2qP","outputId":"885ce0fc-d285-4fa3-af45-87b856350514"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#How many images we have per Automobile category.\nlabels.Type.value_counts().plot.bar(figsize = (30,20), color ='SeaGreen')\n","metadata":{"id":"pbhNP5_qCo7s","outputId":"3ab92d45-8ef6-4897-f71c-0c79ea61fffd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels.Type.value_counts().median()","metadata":{"id":"4NOkEk0kC-2t","outputId":"d5adaa6e-fe8a-4409-e25f-6e184f67fe0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets view images of each category in next few line items\nfrom IPython.display import Image\n","metadata":{"id":"5Pm3rLzYIBwu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Getting images and all their labels\nLets get the images and all their labels","metadata":{"id":"Lt-G1oynOjEk"}},{"cell_type":"code","source":"labels.head()","metadata":{"id":"cXX_TIKaPaFo","outputId":"b0ab7f81-020d-45bd-f159-076be374fd11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create pathnames from Image ID's\nfilename = ['../input/automobilepartsindentification/Automobile-parts/Train/'+fname for fname in labels[\"ID\"]]","metadata":{"id":"B0r1LYwbPb7s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Check whther number of filename matches with actual image files\nimport os\nif len(os.listdir(\"'../input/automobilepartsindentification/Automobile-parts'/Train\")) == len(filename):\n  print(\"File names match actual amount of files, proceed!!!\")\nelse:\n   print(\"File names does not match actual amount of files, check the target directory!!\")","metadata":{"id":"YQOzr440RYfg","outputId":"3764c7a6-41f3-4f78-a1d0-486431d9214b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename[120])","metadata":{"id":"KwYEe2dmtNl0","outputId":"e27e7578-3159-4409-9dc1-ed5ea606dc28"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We have got our training images filepaths in a list, let's prepare our labels","metadata":{"id":"OiVivmP7s9HO"}},{"cell_type":"code","source":"import numpy as np\nlabelnames = labels[\"Type\"].to_numpy()\n#labelnames = np.array(labelnames) ## does same thing as above","metadata":{"id":"t2iwuWPFs9tR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## See if any number of labels matches the number of file names\nif len(labelnames) == len(filename):\n  print(\"Number of labels and number of filenames are matching, Proceed!!!\")\nelse:\n  print(\"Number of labels and number of filenames are not matching, please check the labels\")","metadata":{"id":"UCZAKxS7tXkV","outputId":"624ac999-ca78-4047-d5d4-640b16fd85b6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Find Unique label values\nunique_labels = np.unique(labelnames)\nunique_labels","metadata":{"id":"CW3-ElcHtZbM","outputId":"658dce8b-a1f1-46fa-c098-b45876b8ce89"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labelnames[0], unique_labels[0]","metadata":{"id":"i1N9z6VsthlR","outputId":"d44e0dac-b901-4613-c612-5099a51d943a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn a single label into an array of booleans\nprint(labelnames[0])\nlabelnames[0] == unique_labels\n","metadata":{"id":"3-NakKB4trHV","outputId":"b054fb8e-8c75-44e4-8b28-9b462dfd0f42"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# turn every label into Boolean array\nboolean_labels = [label == unique_labels for label in labelnames]\nlen(boolean_labels)\nprint(boolean_labels)","metadata":{"id":"rZ99S_RyuV0Q","outputId":"37277166-b9e2-42b8-fc83-b48bf26e9534"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turing Boolean Array into integer\nprint(labelnames[300]) # Original label\nprint(np.where(unique_labels == labelnames[1])) # Index where label occurs\nprint(boolean_labels[300].argmax()) # Index where label occurs in boolean array\nprint(boolean_labels[300].astype(int)) # There will be a 1 where the sample label occurs","metadata":{"id":"RWMXngw2u2nv","outputId":"471c7db7-1de7-4501-9734-78bc476bbc34"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating our own validation set\n### we are creating our own validation set as data from Kaggle does not come with validation","metadata":{"id":"7bi7CT_jwEPD"}},{"cell_type":"code","source":"# Setup X and y\nX = filename\ny = boolean_labels","metadata":{"id":"8HPHDuYjwFJm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X), len(y)","metadata":{"id":"clhEDKoGwfIK","outputId":"9847172b-e436-4327-cd23-13c8887d3748"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### We are starting with 40% of the training data set and will increase as needed.\n","metadata":{"id":"3QZazS_Nwts-"}},{"cell_type":"code","source":"NUM_IMAGES = 270 #@param {type:\"slider\", min:150, max:350, step:30}","metadata":{"id":"h48odT6Nw134"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's split the data with training and validation dataset.\nfrom sklearn.model_selection import train_test_split\n# Split them into training and validation of total size of NUM_IMAGE\nX_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES], y[:NUM_IMAGES],\n                                                  test_size =0.1,\n                                                  random_state =42)\nlen(X_train), len(y_train) , len(X_val), len(y_val)","metadata":{"id":"ynfTWEraxNbH","outputId":"40516580-75cf-424f-c982-335d0fe03d9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[:2], y_val[:2]","metadata":{"id":"yLDX0SNrQgsO","outputId":"2e7d15ff-94fd-4306-d532-63f0c7d1e5c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[:2], y_train[:2]","metadata":{"id":"OO2gGAfFx-YH","outputId":"77b313fc-b079-4f9d-e403-a95624d66e07"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing Images - Turning them into **Tensors**\n\nTo preprocess image into Tensors, we are going to write a function which does following things:\n* Take an image file as input\n* Use Tensorflow to read the file save in the variable called `Image`\n* Turn our image into Tensor ( we will convert into PNG).\n* Resize the image to be the shape of 224,224\n* Return the modified Image.\n\n\nLets see what importing an image looks like.","metadata":{"id":"iFOvTC1kzZPg"}},{"cell_type":"code","source":"# Convert an image to a numby array\nfrom matplotlib.pyplot import imread\nimage = imread(filename[300])\nimage.shape","metadata":{"id":"o7LZNrLszGrT","outputId":"a58d805e-e919-49e4-88e9-3bd598bd45cd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image[::2]","metadata":{"id":"CMgSQi3L2b2u","outputId":"dab50106-c62f-4b50-e10e-441e68c46f4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn image into tensor\ntf.constant(image)","metadata":{"id":"QrN87tJr2lkp","outputId":"91b6636f-cabe-4c52-88b3-3a59d59658d6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define size \nIMG_SIZE = 224\n# Create a function for pre-processing image\ndef process_image(image_path, image_size = IMG_SIZE):\n  \"\"\"\n  Takes an image path and turns that image to Tensor\n  \"\"\"\n  #Read in an image file\n  image = tf.io.read_file(image_path)\n\n  #Turn the image to PNG formated numerical Tensor with 3 color channels(Red, Green and Blue)\n  image = tf.image.decode_png(image, channels =3)\n\n  # Convert the color channel values from 0-255 to 0-1\n  image = tf.image.convert_image_dtype(image, tf.float32)\n\n  #Resize the image to our desired value (224, 224)\n\n  image = tf.image.resize(image, size = [IMG_SIZE, IMG_SIZE])\n  return image\n","metadata":{"id":"jn2bXAgu2wDv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Turning data into batches\n","metadata":{"id":"RjLJyANx4p3U"}},{"cell_type":"markdown","source":"#### We need to turn all the data into data batches. we will make a batch of 30 images at a time to avoid any utilization issue and will convert them into batches.\nIn order to use tensor flow effectively,we need our data to be in the form of tensor tuples which may look like `(image, label)`","metadata":{"id":"pfAEj2Oc59e9"}},{"cell_type":"code","source":"# Create a simple function to return tuple\ndef get_image_label(image_path, label):\n  \"\"\"\n  Takes an image path and associated label, process them and returns a tupe of format ( image, label)\n  \"\"\"\n  image = process_image(image_path)\n  return image, label\n","metadata":{"id":"CsnWxAxs4mL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# demo of the above:\nprocess_image(X[300]), tf.constant(y[300])","metadata":{"id":"Pp8flMrx62DN","outputId":"06b4bde8-3810-4f1f-b5ca-0dd96eb746fd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Now we have got a way to turn our data into Tensors in the form ( image, label). Let's make a function to turn all the data ( X , y) into batches","metadata":{"id":"yLZjHnPC8MGo"}},{"cell_type":"code","source":"# Define the batch size as 30\nBATCH_SIZE = 30\n\n#Create a function to turn data into batches\ndef create_data_batches(X, y= None, batch_size = BATCH_SIZE, valid_data = False, test_data = False ):\n  \"\"\"\n  Create a data of batches out of image (X) and label (y) pairs.\n  Shuffles the data if it is training data, does not shuffle it if it is not valid data\n  Also, accepts test data as input.\n  \"\"\"\n  # if the data set is test data set, then probably w don't have labels.\n  if test_data:\n    print(\"Creating test data batches......\")\n    data = tf.data.Dataset.from_tensor_slices(tf.constant(X)) # Only file paths, no labels.\n    data_batch = data.map(process_image).batch(BATCH_SIZE)\n    return data_batch\n  #if the dataset is a valid dataset, we don't need to shuffle it.\n  elif valid_data:\n    print(\"Creating valid data batches....\")\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n                                                      tf.constant(y)))\n    data_batch=data.map(get_image_label).batch(BATCH_SIZE)\n    return data_batch\n  else:\n    print(\"Creating Training Data batches ...........\")  \n    # Turn file paths and labels into Tensors.\n    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),\n                                                      tf.constant(y)))\n\n    #Shuffling the pathnames and labels before mapping image proceesor functions is faster than shuffling image\n    data= data.shuffle(buffer_size = len(X))\n\n    # Create (image, label) tuple and it also turns the image path into a preprocessing image\n    data = data.map(get_image_label)\n\n    #turn training data into batches\n    data_batch = data.batch(BATCH_SIZE)\n    return data_batch","metadata":{"id":"wBeRuys_7sY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create training and validation data batches\ntrain_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val , valid_data = True)","metadata":{"id":"lLdObRBCIvkO","outputId":"b24ba892-a3bf-4fe6-bde3-e14ba057eb4b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, val_data","metadata":{"id":"PZIAxxSlJGgm","outputId":"95e3c1e7-10fd-47b1-ab01-eb407e16795f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualizing different aspect of data batches\ntrain_data.element_spec","metadata":{"id":"E23-LevoRIOJ","outputId":"d7bc3459-09dd-48df-9f7a-35bd6bef6ede"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Our training data is in batches now, hence it is diffcult to understand,let's visualize it.","metadata":{"id":"CCuoVdLJSG_9"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n#create a function to view 30 images as batch\ndef show_30_images(images,labels):\n  \"\"\"\n    Shows 30 images along with their labels\n  \"\"\"\n  #Setup figure\n  plt.figure(figsize=(20,20))\n  #Loop through 30 to show 30 images\n  for i in range(25):\n    #Create subplots\n    ax = plt.subplot(5,5, i+1)\n    #Display image\n    plt.imshow(images[i])\n    plt.title(unique_labels[labels[i].argmax()])\n    #turn gridlines off\n    plt.axis(\"off\")","metadata":{"id":"TWVlOZdrRS09"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if any file is not supported image type\nfrom pathlib import Path\nimport imghdr\n\ndata_dir = \"drive/MyDrive/Automobile/Train/\"\nimage_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n\nimg_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\nfor filepath in Path(data_dir).rglob(\"*\"):\n    if filepath.suffix.lower() in image_extensions:\n        img_type = imghdr.what(filepath)\n        if img_type is None:\n            print(f\"{filepath} is not an image\")\n        elif img_type not in img_type_accepted_by_tf:\n            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")","metadata":{"id":"wEncBoZnhh5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Lets visualize the data in training batch\ntrain_images, train_labels = next(train_data.as_numpy_iterator())\nshow_30_images(train_images, train_labels)","metadata":{"id":"rLjWCj8ji-Fp","outputId":"b58579b4-cb66-4573-f20e-31067c28e77b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"RabGdYX0Surg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now let's visualize our validation set\nval_images, val_label = next(val_data.as_numpy_iterator())\nshow_30_images(val_images,val_label)","metadata":{"id":"eu8yHn4ITov8","outputId":"e25dac3a-6c21-4aef-a230-9eaf9606c19d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"Oz8QQO26piRx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build a model.\nWe need to define below mentioned information before building a model.\n\n1) The Input shape ( shape of our images in form of Tensors).\n\n2) The Output shape( Image labels in the form of Tensor) of our model.\n\n3) The URL model which we want to use from Tensorflow Hub https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\n","metadata":{"id":"liagl98Iw2GS"}},{"cell_type":"code","source":"#Setup Input shape for the model.\nINPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] #[BATCH, HEIGHT, WIDTH, COLOR]\nOUTPUT_SHAPE = len(unique_labels)\n","metadata":{"id":"JIyweW0oy8hs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setup model URL from TensorFlow HUB\nMODEL_URL =\"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/5\"","metadata":{"id":"MJZLa6VP36TW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we have received the input, output and the model ready to go, let's put them together in a keras deep learning. Let's create a function.\n\n* Create a function providing input,output and model.\n* define the layers in Keras model in sequantial function.\n* Compile the model ( it should be evaluated and improved).\n* Returns the model. Steps can be found in https://www.tensorflow.org/guide/keras/sequential_model \n","metadata":{"id":"L1qElB8d2qrA"}},{"cell_type":"code","source":"#Creates a function which builds a Keras model.\ndef create_model(input_shape = INPUT_SHAPE, Output_shape = OUTPUT_SHAPE, model_url = MODEL_URL):\n  \"\"\"\n  Create a Tensorflow Keras Sequantial model\n  \"\"\"\n  print(f\"Building model with: {MODEL_URL}\")\n\n  #Setup model layers:\n  model = tf.keras.Sequential(\n      [\n            hub.KerasLayer(MODEL_URL), #1st Layer (Input Layer)\n            tf.keras.layers.Dense(units = OUTPUT_SHAPE,\n                                  activation = \"softmax\")]) #2nd Layer(Output Layer)\n  #Compile the model\n  model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n                 optimizer = tf.keras.optimizers.Adam(),\n                 metrics =[\"accuracy\"])\n   \n  #Build model.\n  model.build(INPUT_SHAPE)\n  return model\n\n","metadata":{"id":"zbCc1Q3BzksZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = create_model()\nmodel.summary()","metadata":{"id":"i8zp3QTY384b","outputId":"38b93404-ddbf-498e-82c8-55af360831ae"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating call backs.\ncall backs are helper functions a model can use during training to save its progress/ stop training if the model stops improving.\nwe will create 2 call back functions ( 1 for Tensorboards) which will help to track the progress and other for early stopping for preventing our model from training for too long. ","metadata":{"id":"68an51qI7lJ3"}},{"cell_type":"markdown","source":"### Tensorboard callback\nTo load Tensorboard call back, we need to perform 3 things:\n* Load TensorBoard notebook extension.\n* Create a Tensorboard callback which will save logs to a directory and pass it our models `fit()` function.\n* Visualize our model's training logs with `%tensorboard` magic function","metadata":{"id":"HbQJvB4h80Dp"}},{"cell_type":"code","source":"#import Tensorboard magic function\n%load_ext tensorboard\n","metadata":{"id":"xEWnSkZy6_xZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\n#Create a Tensorboard callback which will save logs to a directory and pass it our models fit() function.\ndef create_tensorboard_callback():\n  #Create a log directory to save tensorboard logs\n  logdir = os.path.join(\"drive/MyDrive/Automobile/logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n  return tf.keras.callbacks.TensorBoard(log_dir = logdir)\n  ","metadata":{"id":"9qpZefEI-5Yg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Create a function to build a early stopping callback.\nEarly stoppingn helps our model from overfitting by stopping training if certain evaluation metrics is stopped.\nhttps://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping","metadata":{"id":"k3n584swDMnB"}},{"cell_type":"code","source":"# Create early stopping callback.\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n                                                  patience =3)\n","metadata":{"id":"deVgUqrt_Btj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Training a model on a subset of data.\nOur 1st model is going to train only few images to make sure everything is working.","metadata":{"id":"GRJ1o9vTEkAN"}},{"cell_type":"code","source":"NUM_EPOCHS = 100 #@param {type:\"slider\",min:10,max:100, step:10}\n","metadata":{"id":"z_Wmj_1aEdNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"GPU is available\") if tf.config.list_physical_devices(\"GPU\") else print(\"Not Available\")","metadata":{"id":"4zXyurY-Gc71","outputId":"2a5ae7f8-a585-4852-d2c1-fdeac5ea784c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets create model which trains a model\n* Create a model using `create_model`\n* Setup a tensorboard callback using `create_tensorboard_callback()`\n* call the `fit()`on our model passing it to the training data,validation data,numer of epochs to train under `NUM_EPOCHS` and the callbacks we would like to use.\n* Return the model.","metadata":{"id":"joLwurbFHoea"}},{"cell_type":"code","source":"# Let's create , build and train a model.\ndef train_model():\n  \"\"\"\n    Trains a model and returns it\n  \"\"\"\n  #Create a model.\n  model = create_model()\n\n  # Create a new tensorboard session everytime we train a model.\n  tensorboard = create_tensorboard_callback()\n  #Fit the model to the data passing it to the callbacks we created.\n  model.fit(x = train_data,\n            epochs = NUM_EPOCHS,\n            validation_data = val_data,\n            validation_freq = 1,\n            callbacks = [tensorboard, early_stopping])\n  #Return the fitted model.\n  return model","metadata":{"id":"KCCtiKaNHk4Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model= train_model()","metadata":{"id":"6OqdsEOiKuGr","outputId":"f6fb8ff0-749f-49e4-8b18-408cdc1f18a6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the validation dataset.\npredictions = model.predict(val_data, verbose =1)\npredictions","metadata":{"id":"vpAwQMmoK5c6","outputId":"5ffa4b18-8a91-469b-ad74-7e111d231396"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions.shape","metadata":{"id":"_BtI8BOXxBK3","outputId":"b864f928-d57f-4d16-efe4-9ccc43a21a83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[2]","metadata":{"id":"iJitBaLBxOti","outputId":"4bee7a0b-938a-4938-a2cc-c06ebac8133d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.sum(predictions[2])","metadata":{"id":"Eiau-L2rxGVA","outputId":"cceca258-9fb6-494a-aea6-05f15481335f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# first prediction\nindex = 20\nprint(predictions[index])\nprint(f\"Max value ( Probability of predictions): {np.max(predictions[index])}\")\nprint(f\"Sum:{np.sum(predictions[index])}\")\nprint(f\"Max Index : {np.argmax(predictions[index])}\")\nprint(f\"Predicted Label: {unique_labels[np.argmax(predictions[index])]}\")\n","metadata":{"id":"kdozCzfzxMXZ","outputId":"eaafc577-a04d-4eeb-9238-733609fbf674"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Turn prediction probabilities into their respective labels\ndef get_pred_labels(prediction_probabilities):\n  \"\"\"\n  Turns an array of prediction probabilities into labels\n  \"\"\"\n  return unique_labels[np.argmax(prediction_probabilities)]","metadata":{"id":"C-w_BScDyyXN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a predicted label based on array of prediction probabilities\npred_label = get_pred_labels(predictions[20])\npred_label","metadata":{"id":"uKY1ukFdzefo","outputId":"6b7fd809-2d54-4251-b7a1-4422581b69ad"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data","metadata":{"id":"5KHeTA3r1Ndw","outputId":"00de708c-72c7-400d-f0ff-fb309030960e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Validation data set is in batches, we need to unbatch them to make predictions on validation data set.","metadata":{"id":"hsBdx97v1upp"}},{"cell_type":"code","source":"# Create a function to unbatch a batched Training and Validation dataset.\ndef unbatchify(data):\n  images_ =[]\n  labels_ =[]\n  #Loop through the unbatched data.\n  for image, label in data.unbatch().as_numpy_iterator():\n    images_.append(image)\n    labels_.append(unique_labels[np.argmax(label)])\n  return images_, labels_","metadata":{"id":"5qC6EdbK1T6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a function to unbatch a batched Test dataset.\ndef unbatchify_test(data):\n  images_= []\n  for image in data.unbatch().as_numpy_iterator():\n    images_.append(image)\n  return images_\n","metadata":{"id":"7TmKuivVD5XL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Unbatchify the validation dataset\nval_images, val_label = unbatchify(val_data)","metadata":{"id":"LJwCql0F3eG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_images[0] , val_label[0]","metadata":{"id":"FtFDfNpf3l-l","outputId":"12169944-d75e-424c-bcda-dfddd334f4e1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_pred_labels(val_label[0])","metadata":{"id":"TlfkzNZy3sOI","outputId":"defd2b56-b33c-453a-8536-0222085783ad"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Now we have ways to get:\n* Prediction Labels\n* Validation Labels ( Truth Labels)\n* Validation Images\nLet's make a function to make them more visualizing, we will create a function which will do the following\n* Taken an array of prediction possibilities, array of truth label, an array of image and an integer.\n* Convert the prediction possibilities into the predicted label.\n* Plot the predicted label, its predicted possibilities, the truth label and the target image in a single plot.\n","metadata":{"id":"UAovvThm5bn4"}},{"cell_type":"code","source":"def plot_pred(prediction_possibilities, labels, images, n=26):\n  \"\"\"\n  View predicted label, its predicted possibilities, the truth label and the target image in a single plot\n  \"\"\"\n  pred_prob, true_label, true_image = prediction_possibilities[n], labels[n], images[n]\n  # get the predicted label\n  pred_label = get_pred_labels(pred_prob)\n  # plot images and remove ticks\n  plt.imshow(true_image)\n  plt.xticks=[]\n  plt.yticks=[]\n  if pred_label == true_label:\n    color = \"green\"\n  else:\n    color =\"red\"\n  # Change plot title to get Predicted, Probability of prediction and the truth label\n  plt.title(\"{} {:2.0f}% {}\" .format(pred_label, np.max(pred_prob)*100, true_label),color=color)","metadata":{"id":"FuGX4p8U31QV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" plot_pred(predictions, labels = val_label, images = val_images, n=9)\n  ","metadata":{"id":"rQimP5Y0Dbjb","outputId":"bb69aa4a-3339-4f94-8a45-13ed4fd672ab"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While we have got one more function to visualize our model's top prediction, let's make another view to visualize top 10 prediction of the model.\nThis function will:\n* Take an input with the prediction probabilities array, Ground truth and an integer.\n* Find the prediction using `get_prep_labels()`\n* Find the top 10\n  * Prediction probabilities index\n  * Prection probabilities values\n  * Prediction labels\n* Plot top 10 prediction probabilty values and labels coloring true labels as `green`","metadata":{"id":"f4TgOqn8kCoM"}},{"cell_type":"code","source":"model.evaluate(val_data)","metadata":{"id":"x2dXY29hDpDT","outputId":"d5e1db6e-7184-4c8a-8b5f-76542e85ded3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making predictions on the test dataset.","metadata":{"id":"sWHzLwCrKxiE"}},{"cell_type":"code","source":"#import shutil\n#data_dir = \"drive/MyDrive/Automobile/Test\"\n#shutil.rmtree(data_dir)","metadata":{"id":"Vc74ZIiqaTO8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking if any file is not supported image type on test dataset.\nfrom pathlib import Path\nimport imghdr\n\ndata_dir = '../input/automobilepartsindentification/Automobile-parts\nimage_extensions = [\".png\", \".jpg\"]  # add there all your images file extensions\n\nimg_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\nfor filepath in Path(data_dir).rglob(\"*\"):\n    if filepath.suffix.lower() in image_extensions:\n        img_type = imghdr.what(filepath)\n        if img_type is None:\n            print(f\"{filepath} is not an image\")\n        elif img_type not in img_type_accepted_by_tf:\n            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")","metadata":{"id":"S_nFTDRgFhkS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model with full data.\nfull_data = create_data_batches(X,y)\nfull_data","metadata":{"id":"XwYQBP-ZNNtW","outputId":"2b6a4ac2-fd83-4205-ba95-67855bf09919"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a model.\nfull_model = create_model()","metadata":{"id":"HsrenAEzcae3","outputId":"010fef0e-6c2e-4514-dad2-db661dd86bf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"full_model.summary()","metadata":{"id":"h2VP0PthdbFD","outputId":"4c40f5b2-ad9b-4d3e-a710-9b6626efab8e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_EPOCHS","metadata":{"id":"KLkeRaduh1jv","outputId":"c319281d-161c-4cd2-f13f-386510463e76"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create full model callback\nfull_model_tensorboard = create_tensorboard_callback()\n# No validation set when training on all the data , we cannot monitor accurary\nfull_model_early_stopping = tf.keras.callbacks.EarlyStopping (monitor = \"accuracy\",\n                                                              patience =3)\n# Fit the full model\nfull_model.fit(x= full_data,\n               epochs = NUM_EPOCHS,\n               callbacks = [full_model_tensorboard,full_model_early_stopping ])\n","metadata":{"id":"81KXdDfbdd3p","outputId":"e9b87737-bef9-42be-99f8-689ee4782f99"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load test image data files\ntest_path = \"drive/MyDrive/Automobile/Test/\"\ntest_filename = [test_path + fname for fname in os.listdir(test_path)]\ntest_filename[:10]","metadata":{"id":"YwIcqxEoek__","outputId":"ec82e557-36a8-451f-bf43-fb647793fc14"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nif (os.path.exists(\"'../input/automobilepartsindentification/Automobile-parts/Test/.ipynb_checkpoints\")):\n  shutil.rmtree(\"'../input/automobilepartsindentification/Automobile-parts/Test/.ipynb_checkpoints\")","metadata":{"id":"MCZ8Dvom7r9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\nimport imghdr\n\ndata_dir = \"'../input/automobilepartsindentification/Automobile-parts'Test/\"\nimage_extensions = [\".png\", \".jpg\",\"jpeg\"]  # add there all your images file extensions\n\nimg_type_accepted_by_tf = [\"bmp\", \"gif\", \"jpeg\", \"png\"]\nfor filepath in Path(data_dir).rglob(\"*\"):\n    if filepath.suffix.lower() in image_extensions:\n        img_type = imghdr.what(filepath)\n        if img_type is None:\n            print(f\"{filepath} is not an image\")\n        elif img_type not in img_type_accepted_by_tf:\n            print(f\"{filepath} is a {img_type}, not accepted by TensorFlow\")","metadata":{"id":"FEnCJQuTUphr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir(test_path)))","metadata":{"id":"wHMy7GkAjJo8","outputId":"650b8baa-bc45-4296-b989-19427e105291"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create test data batch\ntest_data_batch = create_data_batches(test_filename, test_data = True)\ntest_data_batch","metadata":{"id":"Jw3KRqsFhQK8","outputId":"05781151-2e41-40e0-ad4a-59772ed86f5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on test data batches\ntest_prediction = full_model.predict(test_data_batch, verbose =1)","metadata":{"id":"vWGctRyBgota","outputId":"a3acdc37-d534-4d0e-d6a2-d0e7469f1686"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prediction[0]","metadata":{"id":"ENXVzdo_nU0n","outputId":"4127ebd4-18d3-4af5-b1f2-bfaeab01840d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image = unbatchify_test(test_data_batch)","metadata":{"id":"QUbsvG-uat8p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_label(prediction_test,images_test,end_batch=30):\n  \"\"\"\n  get the predicted image and predict its label.\n  \"\"\"\n  #Setup figure\n  plt.figure(figsize=(20,20))\n  for i in range(end_batch):\n    #print(i)\n    # plot images and remove ticks\n    ax = plt.subplot(10,10, i+1)\n    plt.imshow(test_image[i])\n    plt.xticks=[]\n    plt.yticks=[]  \n    # Change plot title to get Predicted, Probability of prediction and the truth label\n    plt.title(\"{}\" .format(get_pred_labels(test_prediction[i])))\n    plt.axis(\"off\")","metadata":{"id":"ix53hHqig1p1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_label(prediction_test = test_prediction, images_test = os.listdir(test_path), end_batch=100)","metadata":{"id":"6yA1T3wewddy","outputId":"7cf9329e-64ea-4a56-9460-9574c57d8761"},"execution_count":null,"outputs":[]}]}